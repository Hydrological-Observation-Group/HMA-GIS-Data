{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68e63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b5b39",
   "metadata": {},
   "source": [
    "#### Data 1: lei(2018)_tibet_lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b246ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\courses\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lake_name        date  water_level\n",
      "0  zhariNamco  2010-04-01        0.323\n",
      "1  zhariNamco  2010-04-02        0.322\n",
      "2  zhariNamco  2010-04-03        0.320\n",
      "3  zhariNamco  2010-04-04        0.328\n",
      "4  zhariNamco  2010-04-05        0.310\n"
     ]
    }
   ],
   "source": [
    "path_1 = 'data/ground-observation/lei(2018)_tibet_lakes/tibet_lakes.xlsx'\n",
    "df_1 = pd.read_excel(path_1, usecols=['sno', 'date', 'waterLevel'])\n",
    "df_1 = df_1.rename(columns={'sno': 'lake_name','waterLevel':'water_level'})\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cfe1a",
   "metadata": {},
   "source": [
    "#### Data 2: lei(2022)_tibet_lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd039f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read Lumajiangdong_Co: 1451 行\n",
      "Successfully read Memar_Co: 694 行\n",
      "Successfully read Luotuo_lake: 259 行\n",
      "Successfully read Jieze_Caka: 332 行\n",
      "Total Data:\n",
      "total 2736 rows of data\n",
      "        date  water_level         lake_name\n",
      "0 2016-09-30     0.875692  Lumajiangdong_Co\n",
      "1 2016-10-01     0.876787  Lumajiangdong_Co\n",
      "2 2016-10-02     0.873771  Lumajiangdong_Co\n",
      "3 2016-10-03     0.873217  Lumajiangdong_Co\n",
      "4 2016-10-04     0.866892  Lumajiangdong_Co\n"
     ]
    }
   ],
   "source": [
    "lake_columns_config = {\n",
    "    'Lumajiangdong_Co': {'date_col': 'date', 'water_level_col': 'LMJD_water_level (m)'},\n",
    "    'Memar_Co': {'date_col': 'date', 'water_level_col': 'Memar Co_water_level (m)'},\n",
    "    'Luotuo_lake': {'date_col': 'date', 'water_level_col': 'Luotuo lake_water_level'},\n",
    "    'Jieze_Caka': {'date_col': 'date', 'water_level_col': 'Jieze Caka_water level'}\n",
    "    }\n",
    "\n",
    "def read_lakes_safely(file_path, config):\n",
    "    \n",
    "    df = pd.read_excel(file_path)\n",
    "    lakes_data = {}\n",
    "    for lake_name, cols in config.items():\n",
    "        if all(col in df.columns for col in cols.values()):\n",
    "            lake_df = df[list(cols.values())].dropna().rename(columns=dict(zip(cols.values(), ['date', 'water_level'])))\n",
    "            lake_df['lake_name'] = lake_name\n",
    "            lakes_data[lake_name] = lake_df\n",
    "            print(f\"Successfully read {lake_name}: {lake_df.shape[0]} 行\")\n",
    "        else:\n",
    "            print(f\"{lake_name} does not exist\")\n",
    "    \n",
    "    return lakes_data\n",
    "\n",
    "path_2 = 'data/ground-observation/lei(2022)_tibet_lakes/lei(2022)_tibet_lakes.xlsx'\n",
    "df_2_dict = read_lakes_safely(path_2, lake_columns_config)\n",
    "df_2 = pd.concat(df_2_dict.values(), ignore_index=True)\n",
    "\n",
    "print(\"Total Data:\")\n",
    "print(f\"total {len(df_2)} rows of data\")\n",
    "print(df_2.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a5517",
   "metadata": {},
   "source": [
    "#### Data 3: wang(2018)_namco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230de4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  water_level lake_name\n",
      "0 2007-01-02          NaN     Namco\n",
      "1 2007-01-03          NaN     Namco\n",
      "2 2007-01-04          NaN     Namco\n",
      "3 2007-01-05          NaN     Namco\n",
      "4 2007-01-06          NaN     Namco\n"
     ]
    }
   ],
   "source": [
    "path_3 = 'data/ground-observation/wang(2018)_namco/wang(2018)_namco.xls'\n",
    "df_3 = pd.read_excel(path_3, usecols=['date', 'water_level'])\n",
    "df_3['lake_name'] = 'Namco'\n",
    "df_3['water_level'] = df_3['water_level'] / 100\n",
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e742229",
   "metadata": {},
   "source": [
    "#### Data 4: xie(2021)_kalakuli_lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b535b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integration complete! A total of 834 data points\n",
      "        date  water_level lake_name\n",
      "0 2011-08-23     0.000000  kalakuli\n",
      "1 2011-08-24     0.038735  kalakuli\n",
      "2 2011-08-25     0.073385  kalakuli\n",
      "3 2011-08-26     0.092691  kalakuli\n",
      "4 2011-08-27     0.101668  kalakuli\n"
     ]
    }
   ],
   "source": [
    "path_4 = 'data/ground-observation/xie(2021)_kalakuli_lake/卡拉库里湖水位（2011-2019）.xlsx'\n",
    "column_config = {year: {'date': '时间', 'water': '水位（cm）'} for year in map(str, range(2011, 2020))}\n",
    "\n",
    "result_data = []\n",
    "for year, cols in column_config.items():\n",
    "    try:\n",
    "        df = pd.read_excel(path_4, sheet_name=year)\n",
    "        temp_df = df[list(cols.values())].copy()\n",
    "        temp_df.columns = ['date', 'water_level']\n",
    "        temp_df['lake_name'] = 'kalakuli'\n",
    "        temp_df['water_level'] /= 100  # cm转m\n",
    "        result_data.append(temp_df)\n",
    "    except Exception as e:\n",
    "        print(f\"{year} year failed: {e}\")\n",
    "\n",
    "df_4 = pd.concat(result_data, ignore_index=True) if result_data else pd.DataFrame()\n",
    "print(f\"Integration complete! A total of {len(df_4)} data points\")\n",
    "print(df_4.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f63e5",
   "metadata": {},
   "source": [
    "#### Data 5: zhang2018_silingco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Time Period: 2016-09-17 08:00:00 到 2017-02-15 15:00:00\n",
      "Total number of data points: 3632\n",
      "完整时间序列的水位计算结果：\n",
      "            date      time  water_level lake_name\n",
      "0     2016-09-17  08:00:00     0.160833  silingco\n",
      "1     2016-09-17  09:00:00     0.167652  silingco\n",
      "2     2016-09-17  10:00:00     0.153089  silingco\n",
      "3     2016-09-17  11:00:00     0.210122  silingco\n",
      "4     2016-09-17  12:00:00     0.414559  silingco\n",
      "...          ...       ...          ...       ...\n",
      "3627  2017-02-15  11:00:00     1.209611  silingco\n",
      "3628  2017-02-15  12:00:00     0.970514  silingco\n",
      "3629  2017-02-15  13:00:00     0.677170  silingco\n",
      "3630  2017-02-15  14:00:00     0.640451  silingco\n",
      "3631  2017-02-15  15:00:00     0.611175  silingco\n",
      "\n",
      "[3632 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def read_lake_data(file_path):\n",
    "    \"\"\"read data\"\"\"\n",
    "    df = pd.read_excel(file_path, sheet_name='气象数据集', skiprows=2)\n",
    "    df = df[df.columns[1:4]].copy()\n",
    "    df.columns = ['时间', '压强', '水温']\n",
    "    df['时间'] = df['时间'].apply(lambda x: pd.to_datetime(\n",
    "        str(x).strip().replace('上午', 'AM').replace('下午', 'PM'), \n",
    "        format='%m/%d/%y %p%I时%M分%S秒', errors='coerce'))  # type: ignore\n",
    "    return df.dropna(subset=['时间', '压强', '水温'])\n",
    "\n",
    "def calculate_instant_water_depth(df, altitude=4551, salinity=0):\n",
    "    \"\"\"Calculate the instantaneous water depth for all data points\"\"\"\n",
    "    P_atm = 101325 * (1 - 0.0065 * altitude / 288.15) ** (9.80665 / (287.05 * 0.0065))    \n",
    "\n",
    "    df['瞬时水深'] = df.apply(lambda row: \n",
    "        (row['压强'] * 1000 - P_atm) / \n",
    "        ((1000 * (1 - (row['水温'] + 288.9414) * (row['水温'] - 3.9863)**2 / \n",
    "        (508929.2 * (row['水温'] + 68.12963))) + 0.8 * salinity) * 9.81), axis=1)\n",
    "    \n",
    "    df['日期'] = df['时间'].dt.date\n",
    "    df['时间'] = df['时间'].dt.time\n",
    "    df['lake_name'] = 'silingco'\n",
    "    \n",
    "    result_df = df[['日期', '时间', '瞬时水深', 'lake_name']].copy()\n",
    "\n",
    "    result_df = result_df.rename(columns={\n",
    "        '日期': 'date', \n",
    "        '时间': 'time', \n",
    "        '瞬时水深': 'water_level'\n",
    "    })\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_complete_time_series(df_result):\n",
    "    \"\"\"Create a complete time series with other time columns set to NaN\"\"\"\n",
    "    min_date = df_result['date'].min()\n",
    "    max_date = df_result['date'].max()\n",
    "    all_dates = pd.date_range(start=min_date, end=max_date, freq='D').date\n",
    " \n",
    "    complete_df = pd.DataFrame({\n",
    "        'date': all_dates,\n",
    "        'lake_name': 'silingco'\n",
    "    })\n",
    "    \n",
    "    merged_df = pd.merge(complete_df, df_result, on=['date', 'lake_name'], how='left')\n",
    "    merged_df = merged_df[['date', 'time', 'water_level', 'lake_name']]\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "file_path = \"data/ground-observation/zhang(2018)_silingco/zhang(2018)_silingco.xls\"\n",
    "df = read_lake_data(file_path)\n",
    "\n",
    "print(f\"Data Time Period: {df['时间'].min()} 到 {df['时间'].max()}\")\n",
    "print(f\"Total number of data points: {len(df)}\")\n",
    "\n",
    "df_result = calculate_instant_water_depth(df, altitude=4551)\n",
    "\n",
    "df_5 = create_complete_time_series(df_result)\n",
    "\n",
    "print(\"完整时间序列的水位计算结果：\")\n",
    "print(df_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173855dd",
   "metadata": {},
   "source": [
    "#### Statistics of all in-situ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lake_name\n",
      "Namco               3652\n",
      "silingco            3632\n",
      "zhariNamco          2616\n",
      "BamCo               1461\n",
      "Lumajiangdong_Co    1451\n",
      "PengCo              1257\n",
      "DazegCo             1104\n",
      "DawaCo               867\n",
      "kalakuli             834\n",
      "Memar_Co             694\n",
      "Jieze_Caka           332\n",
      "Luotuo_lake          259\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data saved to: D:\\Desktop\\insitu_code\\hydro_station_lakes_all.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = [df_1, df_2, df_3, df_4, df_5]\n",
    "for i in range(4):  # Add a time column to the first 4 DataFrames\n",
    "    dfs[i]['time'] = np.nan\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "df_all = df_all[['date', 'water_level', 'lake_name', 'time']]\n",
    "df_all['date'] = pd.to_datetime(df_all['date']).dt.strftime('%Y-%m-%d')\n",
    "print(df_all['lake_name'].value_counts())\n",
    "\n",
    "##output\n",
    "output_path = \"data/ground-observation/hydro_station_lakes_all.csv\"\n",
    "df_all.to_csv(output_path, index=False)\n",
    "print(f\"\\nData saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
